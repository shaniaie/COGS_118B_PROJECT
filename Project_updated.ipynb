{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI Heart Disease K-Means Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview - Dori\n",
    "\n",
    "Our group aim to predict the presence of heart disease by clustering on the heart disease datasets. We chose to cluster the data using Unsupervised Machine Learning Algorithm such as K-means, Principal Component Analysis(PCA), and we will perform K-means after PCA. We will use 80% of heart disease data to train the model since and test with the rest 20% of heart disease data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction - Dori\n",
    "We will use heart disease dataset from UCI repository clustering datasets. For the heart disease datasets, it actually has 76 attributes, but we will only be using 14 attributes. The 14 dimensions, which are: age (in years), sex(1=male, 0=female), dataset( where the dataset come from 3 different places such as: V.A. Medical Center, Long Beach and Cleveland), cp( chest pain type: typical angina, atypical angina, non-anginal pain, asymptomatic), trestbps(resting blood pressure in mm Hg on admission to the hospital), chol(serum cholestoral in mg/dl), fbs(fasting blood sugar > 120 mg/dl), restecg(resting electrocardiographic results), thalch(maximum heart rate achieved), exang(exercise induced angina), oldpeak(ST depression induced by exercise relative to rest), slope(the slope of the peak exercise ST segment), ca(number of major vessels from 0-3 colored by flourosopy), thal(normal, fixed defect, reversable defect), and num(diagnosis of heart disease - angiographic disease status). \n",
    "\n",
    "To cluster the data, we will use 2 algorithms which are k-means and principal component analysis(PCA). K-means is a simple but effective algorithm where we will partitions the data in to K cluster and we will update it using iterative batch algorithm. PCA is the simplest method where we will find a linear subspace greatest projected variance and useful to reduced subspace that contains most of the variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Reading CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
       "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
       "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
       "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
       "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
       "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
       "\n",
       "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
       "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
       "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
       "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
       "3          normal   187.0  False      3.5  downsloping  0.0   \n",
       "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
       "\n",
       "                thal  num  \n",
       "0       fixed defect    0  \n",
       "1             normal    2  \n",
       "2  reversable defect    1  \n",
       "3             normal    0  \n",
       "4             normal    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('heart_disease_uci.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning - Shania/Tiffany\n",
    "Removing categorical variables and id\n",
    "\n",
    "Removing entries with missing data\n",
    "\n",
    "Splitting data into 80-20 Train and Test\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           0\n",
       "sex           0\n",
       "dataset       0\n",
       "cp            0\n",
       "trestbps     59\n",
       "chol         30\n",
       "fbs          90\n",
       "restecg       2\n",
       "thalch       55\n",
       "exang        55\n",
       "oldpeak      62\n",
       "slope       309\n",
       "ca          611\n",
       "thal        486\n",
       "num           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns='id', axis=2)\n",
    "# checking columns with the most frequent null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns with the most null values\n",
    "df = df.drop(columns=['ca', 'slope', 'thal'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       920 non-null    int64  \n",
      " 1   sex       920 non-null    object \n",
      " 2   dataset   920 non-null    object \n",
      " 3   cp        920 non-null    object \n",
      " 4   trestbps  861 non-null    float64\n",
      " 5   chol      890 non-null    float64\n",
      " 6   fbs       830 non-null    object \n",
      " 7   restecg   918 non-null    object \n",
      " 8   thalch    865 non-null    float64\n",
      " 9   exang     865 non-null    object \n",
      " 10  oldpeak   858 non-null    float64\n",
      " 11  num       920 non-null    int64  \n",
      "dtypes: float64(4), int64(2), object(6)\n",
      "memory usage: 86.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# checking data frame information after dropping null columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns with categorical values\n",
    "df = df.drop(columns= df.select_dtypes(['object']).columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       920 non-null    int64  \n",
      " 1   trestbps  861 non-null    float64\n",
      " 2   chol      890 non-null    float64\n",
      " 3   thalch    865 non-null    float64\n",
      " 4   oldpeak   858 non-null    float64\n",
      " 5   num       920 non-null    int64  \n",
      "dtypes: float64(4), int64(2)\n",
      "memory usage: 43.2 KB\n"
     ]
    }
   ],
   "source": [
    "# checking data frame information after dropping categorical columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows containing null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 827 entries, 0 to 919\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       827 non-null    int64  \n",
      " 1   trestbps  827 non-null    float64\n",
      " 2   chol      827 non-null    float64\n",
      " 3   thalch    827 non-null    float64\n",
      " 4   oldpeak   827 non-null    float64\n",
      " 5   num       827 non-null    int64  \n",
      "dtypes: float64(4), int64(2)\n",
      "memory usage: 45.2 KB\n"
     ]
    }
   ],
   "source": [
    "# checking final dataframe form after cleaning\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalch</th>\n",
       "      <th>oldpeak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.050186</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>0.291349</td>\n",
       "      <td>0.474814</td>\n",
       "      <td>1.295742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.478336</td>\n",
       "      <td>1.467744</td>\n",
       "      <td>0.773058</td>\n",
       "      <td>-1.152115</td>\n",
       "      <td>0.564039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.478336</td>\n",
       "      <td>-0.635573</td>\n",
       "      <td>0.254994</td>\n",
       "      <td>-0.338651</td>\n",
       "      <td>1.570131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.732793</td>\n",
       "      <td>-0.109744</td>\n",
       "      <td>0.445860</td>\n",
       "      <td>1.908061</td>\n",
       "      <td>2.393296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.304643</td>\n",
       "      <td>-0.109744</td>\n",
       "      <td>0.027772</td>\n",
       "      <td>1.327015</td>\n",
       "      <td>0.472576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>0.943148</td>\n",
       "      <td>1.362578</td>\n",
       "      <td>-0.281249</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>-0.807903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>-0.769454</td>\n",
       "      <td>0.100588</td>\n",
       "      <td>0.991191</td>\n",
       "      <td>-0.454860</td>\n",
       "      <td>-0.807903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0.086847</td>\n",
       "      <td>-0.267493</td>\n",
       "      <td>1.200235</td>\n",
       "      <td>0.629759</td>\n",
       "      <td>-0.807903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>0.193884</td>\n",
       "      <td>-0.530407</td>\n",
       "      <td>0.200460</td>\n",
       "      <td>-1.462007</td>\n",
       "      <td>-0.807903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>0.943148</td>\n",
       "      <td>-0.635573</td>\n",
       "      <td>0.482215</td>\n",
       "      <td>-1.733162</td>\n",
       "      <td>-0.807903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  trestbps      chol    thalch   oldpeak\n",
       "0    1.050186  0.679000  0.291349  0.474814  1.295742\n",
       "1    1.478336  1.467744  0.773058 -1.152115  0.564039\n",
       "2    1.478336 -0.635573  0.254994 -0.338651  1.570131\n",
       "3   -1.732793 -0.109744  0.445860  1.908061  2.393296\n",
       "4   -1.304643 -0.109744  0.027772  1.327015  0.472576\n",
       "..        ...       ...       ...       ...       ...\n",
       "822  0.943148  1.362578 -0.281249  0.009977 -0.807903\n",
       "823 -0.769454  0.100588  0.991191 -0.454860 -0.807903\n",
       "824  0.086847 -0.267493  1.200235  0.629759 -0.807903\n",
       "825  0.193884 -0.530407  0.200460 -1.462007 -0.807903\n",
       "826  0.943148 -0.635573  0.482215 -1.733162 -0.807903\n",
       "\n",
       "[827 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardizing dataset\n",
    "X = df.drop(['num'], axis=1)\n",
    "y = df['num']\n",
    "col = X.columns\n",
    "\n",
    "# perform standard scaler\n",
    "scale = StandardScaler()\n",
    "X = pd.DataFrame(scale.fit_transform(X[col]))\n",
    "X.columns = col\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K - Means - Cory\n",
    "Running K-means with K=5 (num column [0=no heart disease; 1,2,3,4 = stages of heart disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-dependent variables are trestbps, chol, thalch, oldpeak, ca  -> want to see how grouped  \n",
    "-predictions (Y) are num column: diff levels of heart disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* trestbps - resting blood pressure (resting blood pressure (in mm Hg on admission to the hospital))\n",
    "* chol - (serum cholesterol in mg/dl)\n",
    "* thalach - maximum heart rate achieved\n",
    "* oldpeak - ST depression induced by exercise ST segment\n",
    "* ca: number of major vessels (0-3) colored by fluoroscopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcSqDistances(X, Kmus):\n",
    "    # k number of Kmus\n",
    "    #need to find minimum distance from X[][] to Kmus\n",
    "    #need to find closest Kmus and calulate distance\n",
    "    dist = np.zeros((np.shape(X)[0],np.shape(Kmus)[0]))\n",
    "    for k in range(0,Kmus.shape[0]):\n",
    "        for n in range(0,X.shape[0]): # changed from 0\n",
    "            dist[n][k] = (X[n][0]-Kmus[k][0])**2 + (X[n][1]-Kmus[k][1])**2 + (X[n][2]-Kmus[k][2])**2 + (X[n][3]-Kmus[k][3])**2 + (X[n][4]-Kmus[k][4])**2\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineRnk(sqDmat):\n",
    "    m = np.argmin(sqDmat, axis=1)\n",
    "    return np.eye(sqDmat.shape[1])[m] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalcMus(X, Rnk):\n",
    "    # need K newMus\n",
    "    # rnk gives us our binary Rnk matrix saying which points are closest to oldMus\n",
    "    # initialize newMu array to dimension of K columns (usually 2x2)\n",
    "    return (np.divide(X.T.dot(Rnk), np.sum(Rnk, axis=0))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k - means algorithm\n",
    "def runKMeans(K):\n",
    "    # Determine and store data set information\n",
    "    N = np.shape(X)[0]\n",
    "    D = np.shape(X)[1]\n",
    "\n",
    "    # Allocate space for the K mu vectors\n",
    "    Kmus = np.zeros((K, D))\n",
    "\n",
    "    # Initialize cluster centers by randomly picking points from the data\n",
    "    rndinds = np.random.permutation(N)\n",
    "    Kmus = X[rndinds[:K]];\n",
    "\n",
    "    # Specify the maximum number of iterations to allow\n",
    "    maxiters = 1000;\n",
    "\n",
    "    for iter in range(maxiters):\n",
    "        # Assign each data vector to closest mu vector as per Bishop (9.2)\n",
    "        # Do this by first calculating a squared distance matrix where the n,k entry\n",
    "        # contains the squared distance from the nth data vector to the kth mu vector\n",
    "\n",
    "        # sqDmat will be an N-by-K matrix with the n,k entry as specfied above\n",
    "        sqDmat = calcSqDistances(X, Kmus);\n",
    "        # given the matrix of squared distances, determine the closest cluster\n",
    "        # center for each data vector \n",
    "\n",
    "        # R is the \"responsibility\" matrix\n",
    "        # R will be an N-by-K matrix of binary values whose n,k entry is set as \n",
    "        # per Bishop (9.2)\n",
    "        # Specifically, the n,k entry is 1 if point n is closest to cluster k,\n",
    "        # and is 0 otherwise\n",
    "        Rnk = determineRnk(sqDmat)\n",
    "\n",
    "        KmusOld = Kmus\n",
    "        #plotCurrent(X, Rnk, Kmus)\n",
    "        #plt.show()\n",
    "\n",
    "        # Recalculate mu values based on cluster assignments as per Bishop (9.4)\n",
    "        Kmus = recalcMus(X, Rnk)\n",
    "        \n",
    "        # Check to see if the cluster centers have converged.  If so, break.\n",
    "        if sum(abs(KmusOld.flatten() - Kmus.flatten())) < 1e-6:\n",
    "            break\n",
    "            \n",
    "    return Rnk, Kmus\n",
    "    # now we have 5 cluster centers\n",
    "    # we want to see if each num=1's are in the same cluster as expected or not\n",
    "    # Rnk shows us where each datapoint is closest to which cluster\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 16., 210.,  12.,  32., 101.],\n",
       "       [ 23.,  47.,  44.,  58.,  72.],\n",
       "       [ 19.,   4.,  26.,  26.,  24.],\n",
       "       [ 17.,   5.,  17.,  32.,  18.],\n",
       "       [  3.,   1.,   5.,  14.,   1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rnk, Kmus = runKMeans(5)\n",
    "# matrix to tell us which cluster is for what num \n",
    "# how accurate k-means was based on distribution of numbers\n",
    "count = np.zeros((5,5))\n",
    "    \n",
    "for col in range(0,Rnk.shape[1]):\n",
    "    for row in range(0,Rnk.shape[0]):\n",
    "        if (Rnk[row][col] == 1):\n",
    "            if (y[row] == 0):\n",
    "                count[0][col] += 1\n",
    "            elif (y[row] == 1):\n",
    "                count[1][col] += 1\n",
    "            elif (y[row] == 2):\n",
    "                count[2][col] += 1\n",
    "            elif (y[row] == 3):\n",
    "                count[3][col] += 1\n",
    "            elif (y[row] == 4):\n",
    "                count[4][col] += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count matrix rows are for num (diff levels of heart disease) and columns are for 5 cluster centers from K-means.\n",
    "\n",
    "We assume that if data was clustered well, each cluster would have only one num associated with it. Results of count matrix shows that the K-means did not do fairly well since cluster numbers are distributed across different nums."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA - Shahab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigsort(V, eigvals):\n",
    "    # Sort the eigenvalues from largest to smallest. Store the sorted\n",
    "    # eigenvalues in the column vector lambd.\n",
    "    lohival = np.sort(eigvals)\n",
    "    lohiindex = np.argsort(eigvals)\n",
    "    lambd = np.flip(lohival)\n",
    "    index = np.flip(lohiindex)\n",
    "    Dsort = np.diag(lambd)\n",
    "\n",
    "    # Sort eigenvectors to correspond to the ordered eigenvalues. Store sorted\n",
    "    # eigenvectors as columns of the matrix vsort.\n",
    "    M = np.size(lambd)\n",
    "    Vsort = np.zeros((M, M))\n",
    "    for i in range(M):\n",
    "        Vsort[:,i] = V[:,index[i]]\n",
    "    return Vsort, Dsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (5, 661)\n",
      "Mean shape: (5, 1)\n",
      "mean subtracted data: (5, 661)\n",
      "covmatrix: (5, 5)\n",
      "All PCA: (5, 661)\n",
      "2 PCA:  (5, 661)\n",
      "reduced to 2?: (2, 661)\n"
     ]
    }
   ],
   "source": [
    "x = X_train.to_numpy() # maybe wanna change to just X since not using training -> x = X\n",
    "x = x.T\n",
    "print(\"Data shape:\", x.shape)\n",
    "\n",
    "#finds the mean of each dimension\n",
    "mean = np.mean(x, axis=1).reshape(5,1)\n",
    "print(\"Mean shape:\", mean.shape)\n",
    "\n",
    "# calcuclates the matrix of mean subtracted points\n",
    "Z = x - mean\n",
    "print(\"mean subtracted data:\", Z.shape)\n",
    "\n",
    "# calculates the covariance matrix\n",
    "covmatrix = 1/(len(x[0]))*np.matmul(Z,Z.T)\n",
    "print(\"covmatrix:\", covmatrix.shape)\n",
    "\n",
    "#calculates eigenvalues\n",
    "eigvals, V = np.linalg.eig(covmatrix)\n",
    "sortV, sortD = eigsort(V, eigvals)\n",
    "\n",
    "#transforms the entire dataset using all principal components\n",
    "transform = np.matmul(sortV.T, Z)\n",
    "print(\"All PCA:\", transform.shape)\n",
    "\n",
    "#transforms the entire dataset using top 2 principal components\n",
    "best2 = np.matmul(sortV[:,0:2], Z[0:2])\n",
    "print(\"2 PCA: \", best2.shape)\n",
    "\n",
    "#trying to reduce dimensionality with top 2 principal components\n",
    "reduced = np.matmul(sortV[0:2,0:2], Z[0:2])\n",
    "print(\"reduced to 2?:\", reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means after PCA - Cory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Data Analysis - Shadman\n",
    "Run test set on our k-means to get accuracies. Compare these accuracies as well as runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion - Dori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
